import io
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
# from NL import raw_data, model, X_test, cause_encoder, history, processed_df
from MLRF import train_rf_model
from MLSVM import train_svm_model

# Load data
@st.cache_data
def load_data(file_path):
    df = pd.read_csv(file_path)
    
    # à¸à¸³à¸«à¸™à¸”à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¹à¸›à¸¥à¸‡à¹€à¸›à¹‡à¸™à¸•à¸±à¸§à¹€à¸¥à¸‚
    numeric_cols = ["Close/Last", "Open", "High", "Low", "Volume"]

    for col in numeric_cols:
        # à¸¥à¸šà¸ªà¸±à¸à¸¥à¸±à¸à¸©à¸“à¹Œà¸žà¸´à¹€à¸¨à¸© à¹€à¸Šà¹ˆà¸™ $ à¹à¸¥à¸°à¸Šà¹ˆà¸­à¸‡à¸§à¹ˆà¸²à¸‡
        df[col] = df[col].replace({'\\$': '', ' ': ''}, regex=True)
        
        # à¹à¸›à¸¥à¸‡à¹€à¸›à¹‡à¸™ float à¹‚à¸”à¸¢à¸à¸³à¸«à¸™à¸” errors='coerce' à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¹à¸›à¸¥à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¹€à¸›à¹‡à¸™ NaN
        df[col] = pd.to_numeric(df[col], errors='coerce')

    # à¸¥à¸šà¹à¸–à¸§à¸—à¸µà¹ˆà¸¡à¸µà¸„à¹ˆà¸² NaN (à¸–à¹‰à¸²à¸¡à¸µ)
    df.dropna(inplace=True)

    return df
# Sidebar for page selection
page = st.sidebar.radio("Select Page:", [ "Exploration","ðŸ“Š Data", "ðŸ“ˆ Stock Forecasting", "ðŸ¤– Neural Network"])
# ----------------------------- Page 1: Data -----------------------------
if page == "Exploration":
    # Display the title
    st.title("ðŸ“Š Exploration")
    st.write("")
    

# ----------------------------- Page 2: Data -----------------------------
elif page == "ðŸ“Š Data":
    st.title("ðŸ“Š Dataset US Stock From NASDAQ")
    st.markdown("ðŸ”— [Download Dataset](https://www.nasdaq.com/market-activity/stocks/msft/historical?page=1&rows_per_page=10&timeline=y1)")
    
    # à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¸«à¸£à¸·à¸­à¹ƒà¸Šà¹‰à¹„à¸Ÿà¸¥à¹Œà¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡
    uploaded_file = st.file_uploader("Upload your CSV file (Optional)", type=["csv"])
    if uploaded_file is not None:
        df = load_data(uploaded_file)
    else:
        file_path = "NVDA.csv"
        df = load_data(file_path)
    
    tab1, tab2, tab3, tab4 = st.tabs(["ðŸ“Š Summarize Data", "ðŸ“ˆ Data Demo", "SVM", "RF"])
    
    with tab1:
        st.write("### ðŸ”¹ Features in Dataset")
        
        feature_descriptions = {
            "Date": "ðŸ“… à¸§à¸±à¸™à¸—à¸µà¹ˆà¸—à¸µà¹ˆà¸šà¸±à¸™à¸—à¸¶à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ (MM/DD/YYYY)",
            "Close/Last": "ðŸ’° à¸£à¸²à¸„à¸²à¸›à¸´à¸”à¸‚à¸­à¸‡à¸«à¸¸à¹‰à¸™à¹ƒà¸™à¸§à¸±à¸™à¸™à¸±à¹‰à¸™",
            "Volume": "ðŸ“Š à¸›à¸£à¸´à¸¡à¸²à¸“à¸à¸²à¸£à¸‹à¸·à¹‰à¸­à¸‚à¸²à¸¢à¸«à¸¸à¹‰à¸™à¹ƒà¸™à¸§à¸±à¸™à¸™à¸±à¹‰à¸™",
            "Open": "ðŸš€ à¸£à¸²à¸„à¸²à¹€à¸›à¸´à¸”à¸‚à¸­à¸‡à¸«à¸¸à¹‰à¸™à¹ƒà¸™à¸§à¸±à¸™à¸™à¸±à¹‰à¸™",
            "High": "ðŸ“ˆ à¸£à¸²à¸„à¸²à¸ªà¸¹à¸‡à¸ªà¸¸à¸”à¸‚à¸­à¸‡à¸«à¸¸à¹‰à¸™à¹ƒà¸™à¸§à¸±à¸™à¸™à¸±à¹‰à¸™",
            "Low": "ðŸ“‰ à¸£à¸²à¸„à¸²à¸•à¹ˆà¸³à¸ªà¸¸à¸”à¸‚à¸­à¸‡à¸«à¸¸à¹‰à¸™à¹ƒà¸™à¸§à¸±à¸™à¸™à¸±à¹‰à¸™"
        }
        
        for col in df.columns:
            if col in feature_descriptions:
                st.write(f"**{col}** - {feature_descriptions[col]}")

        st.write("### ðŸ“Š Summary Statistics")
        st.write(df.describe())

        st.write("### ðŸ›  Data Cleaning Process")
        st.write("1. à¸¥à¸šà¹à¸–à¸§à¸—à¸µà¹ˆà¸¡à¸µà¸„à¹ˆà¸² Missing Values")
        st.write("2. à¹à¸›à¸¥à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¹‰à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸£à¸¹à¸›à¹à¸šà¸šà¸—à¸µà¹ˆà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡")
        st.write("3. à¸„à¸³à¸™à¸§à¸“à¹€à¸›à¸­à¸£à¹Œà¹€à¸‹à¹‡à¸™à¸•à¹Œà¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸‚à¸­à¸‡à¸£à¸²à¸„à¸²")
        st.write("4. à¹à¸ªà¸”à¸‡à¸à¸£à¸²à¸Ÿà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸±à¸‡à¸—à¸³à¸„à¸§à¸²à¸¡à¸ªà¸°à¸­à¸²à¸”")
        

        # à¸à¸³à¸«à¸™à¸”à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¹à¸›à¸¥à¸‡à¹€à¸›à¹‡à¸™à¸•à¸±à¸§à¹€à¸¥à¸‚
        numeric_cols = ["Close/Last", "Volume", "Open", "High", "Low"]
        
        # à¸¥à¸šà¸ªà¸±à¸à¸¥à¸±à¸à¸©à¸“à¹Œà¸žà¸´à¹€à¸¨à¸© à¹€à¸Šà¹ˆà¸™ "$" à¹à¸¥à¸°à¸Šà¹ˆà¸­à¸‡à¸§à¹ˆà¸²à¸‡ à¹à¸¥à¹‰à¸§à¹à¸›à¸¥à¸‡à¹€à¸›à¹‡à¸™ float à¸­à¸¢à¹ˆà¸²à¸‡à¸›à¸¥à¸­à¸”à¸ à¸±à¸¢
        for col in numeric_cols:
            df[col] = df[col].replace({'\$': '', ',': '', ' ': ''}, regex=True)
            df[col] = pd.to_numeric(df[col], errors='coerce')  # à¹ƒà¸Šà¹‰ pd.to_numeric() à¹€à¸žà¸·à¹ˆà¸­à¸«à¸¥à¸µà¸à¹€à¸¥à¸µà¹ˆà¸¢à¸‡à¸‚à¹‰à¸­à¸œà¸´à¸”à¸žà¸¥à¸²à¸”


        # à¸¥à¸šà¹à¸–à¸§à¸—à¸µà¹ˆà¸¡à¸µà¸„à¹ˆà¸² NaN
        df_cleaned = df.dropna()



        # à¸„à¸³à¸™à¸§à¸“à¹€à¸›à¸­à¸£à¹Œà¹€à¸‹à¹‡à¸™à¸•à¹Œà¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸‚à¸­à¸‡à¸£à¸²à¸„à¸²
        df_cleaned["Price Change (%)"] = ((df_cleaned["Close/Last"] - df_cleaned["Open"]) / df_cleaned["Open"]) * 100

        st.write("### ðŸ“‰ Daily Price Change Percentage (à¸«à¸¥à¸±à¸‡à¸—à¸³à¸„à¸§à¸²à¸¡à¸ªà¸°à¸­à¸²à¸”)")
        st.write(df_cleaned[["Date", "Open", "Close/Last", "Price Change (%)"]])

        # à¹à¸ªà¸”à¸‡à¸à¸£à¸²à¸Ÿà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸±à¸‡à¸—à¸³à¸„à¸§à¸²à¸¡à¸ªà¸°à¸­à¸²à¸”
        fig = px.line(df_cleaned, x="Date", y="Price Change (%)", title="ðŸ“‰ Daily Price Change (%) Over Time (à¸«à¸¥à¸±à¸‡à¸—à¸³à¸„à¸§à¸²à¸¡à¸ªà¸°à¸­à¸²à¸”)")
        st.plotly_chart(fig)
        
        st.write("## Why using Boxplot manage outlier ?")
        st.write("ðŸ“Š à¹ƒà¸Šà¹‰ Boxplot à¹€à¸žà¸·à¹ˆà¸­à¹à¸ªà¸”à¸‡à¸à¸²à¸£à¸à¸£à¸°à¸ˆà¸²à¸¢à¸•à¸±à¸§à¸‚à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ à¹à¸¥à¸°à¸Šà¹ˆà¸§à¸¢à¹ƒà¸™à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸„à¹ˆà¸² Outliers à¹ƒà¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥")
        st.image("asset/Boxplot.png", use_container_width=True)
        st.write("ðŸ” à¸ˆà¸²à¸à¸à¸£à¸²à¸Ÿ Boxplot à¸ˆà¸°à¹€à¸«à¹‡à¸™à¹„à¸”à¹‰à¸§à¹ˆà¸²à¸¡à¸µà¸„à¹ˆà¸² Outliers à¸—à¸µà¹ˆà¸¡à¸µ Upper = Q3 + 1.5 * IQR à¹à¸¥à¸° Lower = Q1 - 1.5 * IQR")
        
        



    with tab2:
        st.write("### ðŸ“Œ Raw Data (Before Cleaning)")
        st.write(df.head())
    
        # à¸•à¸±à¸§à¹€à¸¥à¸·à¸­à¸à¸à¸²à¸£à¸—à¸³ Data Cleaning
        st.subheader("ðŸ› ï¸ Choose Data Cleaning Method")
        remove_duplicates = st.checkbox("ðŸ—‘ï¸ Remove Duplicate Rows")
        remove_outliers = st.checkbox("ðŸ“‰ Remove Outliers (IQR Method)")
        
        # à¸—à¸³ Data Cleaning
        df_cleaned = df.copy()
        
        # à¸¥à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸‹à¹‰à¸³à¸‹à¹‰à¸­à¸™
        if remove_duplicates:
            df_cleaned = df_cleaned.drop_duplicates()
        

        
        # à¸¥à¸šà¸„à¹ˆà¸² Outliers
        if remove_outliers:
            Q1, Q3 = df_cleaned["Volume"].quantile([0.25, 0.75])
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            df_cleaned = df_cleaned[(df_cleaned["Volume"] >= lower_bound) & (df_cleaned["Volume"] <= upper_bound)]
        
        # à¹à¸ªà¸”à¸‡à¸œà¸¥à¸«à¸¥à¸±à¸‡à¸—à¸³ Data Cleaning
        st.write("### âœ… Cleaned Data (After Cleaning)")
        st.write(df_cleaned.head())
        
        # à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸ˆà¸³à¸™à¸§à¸™à¹à¸–à¸§à¸à¹ˆà¸­à¸™à¹à¸¥à¸°à¸«à¸¥à¸±à¸‡à¸—à¸³à¸„à¸§à¸²à¸¡à¸ªà¸°à¸­à¸²à¸”
        st.write(f"ðŸ“Š Data Before Cleaning: {df.shape[0]} rows")
        st.write(f"ðŸ“Š Data After Cleaning: {df_cleaned.shape[0]} rows")
        
        # à¹à¸ªà¸”à¸‡à¸à¸£à¸²à¸Ÿà¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸à¸²à¸£à¸à¸£à¸°à¸ˆà¸²à¸¢à¸•à¸±à¸§à¸‚à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
        st.subheader("ðŸ”Ž Data Distribution Before vs After Cleaning")
        fig_before = px.box(df, y=["Close/Last", "Open", "High", "Low", "Volume"], title="Before Cleaning")
        fig_after = px.box(df_cleaned, y=["Close/Last", "Open", "High", "Low", "Volume"], title="After Cleaning")
        st.plotly_chart(fig_before)
        st.plotly_chart(fig_after)
        
        st.write("âœ… **Data Cleaning Completed!**")
    
    with tab3:
        st.write("### SVM Algorithm")
        st.write("à¸„à¸·à¸­ à¹€à¸›à¹‡à¸™à¸«à¸™à¸¶à¹ˆà¸‡à¹ƒà¸™à¸­à¸±à¸¥à¸à¸­à¸£à¸´à¸˜à¸¶à¸¡à¸à¸²à¸£à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¸‚à¸­à¸‡à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡ (Machine Learning) à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸ªà¸³à¸«à¸£à¸±à¸š Classification à¹à¸¥à¸° Regression à¹‚à¸”à¸¢à¹€à¸‰à¸žà¸²à¸°à¸­à¸¢à¹ˆà¸²à¸‡à¸¢à¸´à¹ˆà¸‡à¹ƒà¸™à¸‡à¸²à¸™à¸—à¸µà¹ˆà¸¡à¸µà¸‚à¸™à¸²à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹„à¸¡à¹ˆà¹ƒà¸«à¸à¹ˆà¸¡à¸²à¸à¹à¸¥à¸°à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³à¸ªà¸¹à¸‡")
        st.write("1. Hyperplane")

# ----------------------------- Page 3: Stock Forecasting -----------------------------
elif page == "ðŸ“ˆ Stock Forecasting":
    st.title("ðŸ“ˆ NVIDIA Stock Price Forecasting")

    # Choose to upload a file or use the demo file
    uploaded_file = st.file_uploader("Upload your CSV file (Optional)", type=["csv"])
    if uploaded_file is not None:
        df = load_data(uploaded_file)
    else:
        # Default demo file
        file_path = "NVDA.csv"
        df = load_data(file_path)

    # Remove outliers
    Q1, Q3 = df["Volume"].quantile([0.25, 0.75])
    IQR = Q3 - Q1
    lower_bound, upper_bound = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR
    df_cleaned = df[(df["Volume"] >= lower_bound) & (df["Volume"] <= upper_bound)]

    # à¸—à¸³à¸™à¸²à¸¢à¸œà¸¥à¸”à¹‰à¸§à¸¢à¹‚à¸¡à¹€à¸”à¸¥ SVM à¹à¸¥à¸° RF
    y_test_svm, y_pred_svm, mae_svm = train_svm_model(df_cleaned)
    y_test_rf, y_pred_rf, mae_rf = train_rf_model(df_cleaned)

    # à¹à¸ªà¸”à¸‡à¸„à¹ˆà¸² MAE
    st.write(f"âœ… **SVM Mean Absolute Error:** {mae_svm:.8f}")
    st.write(f"âœ… **Random Forest Mean Absolute Error:** {mae_rf:.8f}")

    # à¸„à¸³à¸™à¸§à¸“à¸„à¹ˆà¸²à¸ªà¸¹à¸‡à¸ªà¸¸à¸” (Max), à¸„à¹ˆà¸²à¹€à¸‰à¸¥à¸µà¹ˆà¸¢ (Avg), à¹à¸¥à¸°à¸„à¹ˆà¸²à¸•à¹ˆà¸³à¸ªà¸¸à¸” (Min)
    svm_max, svm_avg, svm_min = np.max(y_pred_svm), np.mean(y_pred_svm), np.min(y_pred_svm)
    rf_max, rf_avg, rf_min = np.max(y_pred_rf), np.mean(y_pred_rf), np.min(y_pred_rf)

    # à¹à¸ªà¸”à¸‡à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸ˆà¸²à¸à¹‚à¸¡à¹€à¸”à¸¥ SVM à¹à¸¥à¸° RF à¸žà¸£à¹‰à¸­à¸¡à¸à¸£à¸²à¸Ÿ
    st.subheader("ðŸ“‰ Model Prediction Comparison")
    tab1, tab2 = st.tabs(["ðŸ”´ SVM Predictions", "ðŸŸ¢ Random Forest Predictions"])
    
    with tab1:
        st.markdown("### ðŸ”´ SVM Model")
        st.write(f"ðŸ“Œ **Max Price:** ${svm_max:.2f}")
        st.write(f"ðŸ“Œ **Avg Price:** ${svm_avg:.2f}")
        st.write(f"ðŸ“Œ **Min Price:** ${svm_min:.2f}")

        fig_svm = px.scatter(x=y_test_svm, y=y_pred_svm, labels={"x": "True Price", "y": "Predicted Price"},
                                title="SVM: Predicted vs True Price", color_discrete_sequence=["red"])
        st.plotly_chart(fig_svm)

    with tab2:
        st.markdown("### ðŸŸ¢ Random Forest Model")
        st.write(f"ðŸ“Œ **Max Price:** ${rf_max:.2f}")
        st.write(f"ðŸ“Œ **Avg Price:** ${rf_avg:.2f}")
        st.write(f"ðŸ“Œ **Min Price:** ${rf_min:.2f}")

        fig_rf = px.scatter(x=y_test_rf, y=y_pred_rf, labels={"x": "True Price", "y": "Predicted Price"},
                            title="Random Forest: Predicted vs True Price", color_discrete_sequence=["green"])
        st.plotly_chart(fig_rf)

# ----------------------------- Page 4: Neural Network -----------------------------
# elif page == "ðŸ¤– Neural Network":
#     st.title("ðŸ¤– Accident Prediction")
    
#     # à¹à¸ªà¸”à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸”à¸´à¸šà¸à¹ˆà¸­à¸™à¸à¸²à¸£ encode
#     if st.checkbox("ðŸ” Show Raw Data"):
#         st.subheader("ðŸ“Š Raw Data")
#         st.write(raw_data.head())  # à¹à¸ªà¸”à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸”à¸´à¸šà¸—à¸µà¹ˆà¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸—à¸³à¸à¸²à¸£ encode
    
#     tab1, tab2, tab3, tab4 = st.tabs(["ðŸ“Š Training History", "ðŸ“ˆ Cause Prediction Accuracy", "ðŸ”¥ Feature Correlation", "ðŸ§  Sample Predictions"])
    
#     with tab1:
#         st.subheader("ðŸ“Š Training History")
#         fig = go.Figure()
#         fig.add_trace(go.Scatter(y=history.history['loss'], mode='lines+markers', name='Total Loss'))
#         fig.add_trace(go.Scatter(y=history.history['val_loss'], mode='lines+markers', name='Validation Loss'))
#         fig.update_layout(xaxis_title='Epochs', yaxis_title='Loss', template='plotly_dark')
#         st.plotly_chart(fig)
    
#     with tab2:
#         st.subheader("ðŸ“ˆ Cause Prediction Accuracy")
#         fig = go.Figure()
#         fig.add_trace(go.Scatter(y=history.history['cause_output_accuracy'], mode='lines+markers', name='Train Accuracy'))
#         fig.add_trace(go.Scatter(y=history.history['val_cause_output_accuracy'], mode='lines+markers', name='Validation Accuracy'))
#         fig.update_layout(xaxis_title='Epochs', yaxis_title='Accuracy', template='plotly_dark')
#         st.plotly_chart(fig)
    
#     with tab3:
#         st.subheader("ðŸ”¥ Feature Correlation Heatmap")
#         fig, ax = plt.subplots(figsize=(10, 6))
#         sns.heatmap(processed_df.corr(), annot=True, fmt='.2f', cmap='coolwarm', linewidths=0.5, ax=ax)
#         st.pyplot(fig)
    
#     with tab4:
#         st.subheader("ðŸ§  Sample Predictions")
#         sample_data = np.array(X_test.iloc[:5])
#         predicted_causes, predicted_casualties = model.predict(sample_data)
#         predicted_causes = np.argmax(predicted_causes, axis=1)
#         predicted_causes = cause_encoder.inverse_transform(predicted_causes)
#         predicted_casualties = predicted_casualties.flatten()
        
#         predictions_df = pd.DataFrame({
#             "Predicted Cause": predicted_causes,
#             "Predicted Casualties": predicted_casualties
#         })
#         st.dataframe(predictions_df.style.format({"Predicted Casualties": "{:.0f}"}).set_properties(**{'text-align': 'center'}))
